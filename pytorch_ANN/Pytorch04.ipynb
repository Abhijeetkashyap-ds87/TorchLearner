{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Pytorch + Optuna"
      ],
      "metadata": {
        "id": "Rwr3JYqOQR_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An open source hyperparameter optimization framework to automate hyperparameter search"
      ],
      "metadata": {
        "id": "drnLtvYoRBxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDXC5y7tVVQ6",
        "outputId": "be96ebe8-cbbd-422f-c840-92d653f35b21"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGRxT6RiyOF1",
        "outputId": "8834aac7-b6ad-4423-b77d-4c88b3647c49"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.11/dist-packages (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.15.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import optuna\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import torch.optim as optimizer\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder,OrdinalEncoder,FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,KFold\n",
        "import category_encoders as ce\n",
        "from sklearn.metrics import r2_score, mean_squared_error"
      ],
      "metadata": {
        "id": "tZirEClZxzdp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intial setup"
      ],
      "metadata": {
        "id": "H9GeZxTaESKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/content/modified.csv')"
      ],
      "metadata": {
        "id": "hdpt6rnEDUJq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=np.log1p(data['price'])\n",
        "x=data.drop(columns=['price'],axis=1)"
      ],
      "metadata": {
        "id": "JYozm5rFDdwX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "x_train_final, x_val, y_train_final, y_val = train_test_split(\n",
        "    x_train, y_train, test_size=0.2, random_state=42)\n",
        "print(type(x_train_final),x_train_final.shape)\n",
        "print(type(x_val),x_val.shape)\n",
        "print(type(x_test),x_test.shape)\n",
        "print(type(y_train_final),y_train_final.shape)\n",
        "print(type(y_val),y_val.shape)\n",
        "print(type(y_test),y_test.shape)"
      ],
      "metadata": {
        "id": "Av4SZ8JsDoo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1baf1ee-3efb-4555-b862-628e93bca5c0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'> (2435, 12)\n",
            "<class 'pandas.core.frame.DataFrame'> (609, 12)\n",
            "<class 'pandas.core.frame.DataFrame'> (761, 12)\n",
            "<class 'pandas.core.series.Series'> (2435,)\n",
            "<class 'pandas.core.series.Series'> (609,)\n",
            "<class 'pandas.core.series.Series'> (761,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transformation\n",
        "def transformation():\n",
        "\n",
        "  transformer=ColumnTransformer(transformers=[\n",
        "    ('tnf1',OneHotEncoder(drop='first',sparse_output=False,),['agePossession','type']),\n",
        "    ('tnf2',OrdinalEncoder(categories=[['no','yes']]),['servant room']),\n",
        "    ('tnf3',OrdinalEncoder(categories=[['no','yes']]),['pooja room']),\n",
        "     ('tnf4',OrdinalEncoder(categories=[['groundfloor','mid floor','high floor','low floor','hometop']]),['floor_type']),\n",
        "    ('tnf5',OrdinalEncoder(categories=[['low','normal','semi_luxrious','luxrious']]),['luxury']),\n",
        "    ('tnf6',OrdinalEncoder(categories=[['1','0','2','3','3+']]),['balcony']),\n",
        "    ('tnf7',OrdinalEncoder(categories=[['unfurnished', 'semifurnished', 'furnished']]),['furnishing_type']),\n",
        "    ('tnf8',ce.TargetEncoder(),['sector']),\n",
        "    ('tnf9',StandardScaler(),['built_up_area'])\n",
        "    ],remainder='passthrough')\n",
        "\n",
        "  return transformer"
      ],
      "metadata": {
        "id": "wVbG0347EBoW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer=transformation()\n",
        "transformer.fit(x_train_final,y_train_final) # y_train required for target encoder\n",
        "x_train_transformed=transformer.transform(x_train_final)\n",
        "x_val_transform=transformer.transform(x_val)\n",
        "x_test_transformed=transformer.transform(x_test)\n",
        "print(type(x_train_transformed),x_train_transformed.shape)\n",
        "print(type(x_val_transform),x_val_transform.shape)\n",
        "print(type(x_test_transformed),x_test_transformed.shape)"
      ],
      "metadata": {
        "id": "DH9shNLCEHdk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc1023d-f8f8-4d14-f155-c3de6b5144d7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> (2435, 15)\n",
            "<class 'numpy.ndarray'> (609, 15)\n",
            "<class 'numpy.ndarray'> (761, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changing into numpy array\n",
        "y_train_final=y_train_final.values\n",
        "y_val=y_val.values\n",
        "y_test=y_test.values"
      ],
      "metadata": {
        "id": "X7TzrEXnKt3A"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ANN + optuna"
      ],
      "metadata": {
        "id": "ai_pVIFiEWdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# customdataset\n",
        "class customdataset(Dataset):\n",
        "  def __init__(self,x,y):\n",
        "    self.x_tensor=torch.tensor(x,dtype=torch.float32)\n",
        "    self.y_tensor=torch.tensor(y,dtype=torch.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.x_tensor.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    return self.x_tensor[index],self.y_tensor[index]"
      ],
      "metadata": {
        "id": "xqoKfMkbHpTP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making dataset_object\n",
        "train_data=customdataset(x_train_transformed,y_train_final)\n",
        "valid_data=customdataset(x_val_transform,y_val)"
      ],
      "metadata": {
        "id": "fHzjLREKXqNY"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking device avilability\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "aQCq7NECa7IK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f0977a-ea93-461e-fe69-ec4c09c8eccf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "num_hidden_layers,\n",
        "num_nueron_layer,\n",
        "batchnorm,\n",
        "dropout,\n",
        "batch_size,\n",
        "activation function'''"
      ],
      "metadata": {
        "id": "BbQZks6eVhdG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "30029bb6-9d3d-4c42-cc60-071f76aaa48c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nnum_hidden_layers,\\nnum_nueron_layer,\\nbatchnorm,\\ndropout,\\nbatch_size,\\nactivation function'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defning custom Ann subclass\n",
        "class customAnn(nn.Module):\n",
        "\n",
        "  # intialization\n",
        "  def __init__(\n",
        "              self,input_dim,output_dim,\n",
        "              num_hidden_layers,nueron_per_layer,\n",
        "              activation,\n",
        "              batch_bool,drop_bool,\n",
        "              drop_rate\n",
        "              ):\n",
        "    super().__init__()\n",
        "\n",
        "    layers=[]\n",
        "\n",
        "    for i in range(num_hidden_layers):\n",
        "      '''\n",
        "      num_hidden_layers = 4 in ist trial\n",
        "      so this loop as for i in range(4):\n",
        "          i=0 # ist hidden layer\n",
        "          i=1 # 2nd hidden layer\n",
        "          i=2 # 3rd hidden layer\n",
        "          i=3 # 4th hidden layer\n",
        "      again in next trial optuna picks 5 as given in search_space\n",
        "\n",
        "      '''\n",
        "      out_feature=nueron_per_layer[i]\n",
        "      '''\n",
        "      (from objective function)\n",
        "      nueron_per_layer = []\n",
        "      for i in range(num_hidden_layers):\n",
        "        if i == 0:\n",
        "        nueron = 16  # Simulated trial.suggest_int('nueron_per_layer0', 10, 18, step=2)\n",
        "        else:\n",
        "          nueron = 12  # Simulated trial.suggest_int('nueron_per_layer{i}', 2, 18, step=2)\n",
        "\n",
        "      nueron_per_layer.append(nueron)\n",
        "\n",
        "      output:\n",
        "      nueron_per_layer = [16, 12, 12, 12, 12]\n",
        "\n",
        "      so we select as out_feature=nueron_per_layer[i] for each layer\n",
        "      ist hidden layer = nueron_per_layer[i] i=0 : out_feature=16 and so_on____\n",
        "\n",
        "      '''\n",
        "      # defining architecture of a hidden layer\n",
        "      layers.append(nn.Linear(out_features=out_feature,in_features=input_dim))\n",
        "\n",
        "      if drop_bool:\n",
        "        layers.append(nn.Dropout1d(drop_rate))\n",
        "      if batch_bool:\n",
        "        layers.append(nn.BatchNorm1d(out_feature,affine=True))\n",
        "\n",
        "      if activation=='ReLU':\n",
        "        layers.append(nn.ReLU())\n",
        "\n",
        "      elif activation=='LeakyReLU':\n",
        "        layers.append(nn.LeakyReLU())\n",
        "\n",
        "      elif activation=='GELU':\n",
        "        layers.append(nn.GELU())\n",
        "\n",
        "      input_dim=out_feature\n",
        "\n",
        "    # ouptut layer\n",
        "    layers.append(nn.Linear(out_features=1,in_features=input_dim))\n",
        "\n",
        "    self.model=nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "  def forward(self,x_train_transformed):\n",
        "    x_tensor=torch.tensor(x_train_transformed,dtype=torch.float32)\n",
        "\n",
        "    return self.model(x_tensor).squeeze(dim=1)"
      ],
      "metadata": {
        "id": "tYb1RhZjEeY4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(parameter):\n",
        "      # Intialized weights and bias\n",
        "      if isinstance(parameter,nn.Linear):\n",
        "        init.kaiming_uniform_(parameter.weight, nonlinearity='relu')\n",
        "\n",
        "        if parameter.bias is  not None:\n",
        "          init.zeros_(parameter.bias)\n",
        "\n",
        "      # intializing gamma and betta of batchnorm\n",
        "      elif isinstance(parameter,nn.BatchNorm1d):\n",
        "        init.ones_(parameter.weight)\n",
        "        init.zeros_(parameter.bias)"
      ],
      "metadata": {
        "id": "Zt8AOQtvba2_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# global_list for storing logs\n",
        "train_r2_list = []\n",
        "val_r2_list = []\n",
        "trial_numbers = []\n",
        "\n",
        "def objective(trial):\n",
        "  #  defining hyperparameter and it's search space\n",
        "\n",
        "  ''' Pick an integer between 4 and 8 (inclusive) for\n",
        "   the num_hidden_layers parameter.'''\n",
        "  num_hidden_layers=trial.suggest_int('num_hidden_layers',4,8)\n",
        "\n",
        "  '''\n",
        "  Defining no.of nuerons per layer and storing trial object into\n",
        "  nueron_per_layer list\n",
        "  '''\n",
        "  nueron_per_layer=[]\n",
        "\n",
        "  for i in range(num_hidden_layers):\n",
        "    if i==0: # ist hidden layer input_dim =15\n",
        "      nueron=trial.suggest_int(f'nueron_per_layer{i}',10,18,step=2)\n",
        "    else:\n",
        "      nueron=trial.suggest_int(f'nueron_per_layer{i}',2,18,step=2)\n",
        "\n",
        "    nueron_per_layer.append(nueron)\n",
        "\n",
        "  # batch_size\n",
        "  batch_size=trial.suggest_categorical('batch_size',[64,128])\n",
        "\n",
        "  # param init\n",
        "  activation_name = trial.suggest_categorical('activation', ['ReLU', 'LeakyReLU','GELU'])\n",
        "  batch_norm=trial.suggest_categorical('batch1dnorm',[True,False])\n",
        "  drop_layer=trial.suggest_categorical('drop1d',[True,False])\n",
        "  learning_rate=trial.suggest_float('learning_rate',1e-4,1e-1,log=True)\n",
        "  keep_prob=trial.suggest_float('keep_prob',0.1,0.8)\n",
        "  drop_rate=1-keep_prob\n",
        "  epochs=trial.suggest_int('No.of.epochs',100,1000,step=100)\n",
        "\n",
        "  # model init\n",
        "  input_dim=15\n",
        "  output_dim=1\n",
        "  model=customAnn(\n",
        "      input_dim=input_dim,\n",
        "      output_dim=output_dim,\n",
        "      num_hidden_layers=num_hidden_layers,\n",
        "      nueron_per_layer=nueron_per_layer,\n",
        "      activation=activation_name,\n",
        "      batch_bool=batch_norm,\n",
        "      drop_bool=drop_layer,\n",
        "      drop_rate=drop_rate,\n",
        "\n",
        "\n",
        "  ).apply(init_weights).to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # DataLLoader\n",
        "  train_loader=DataLoader(train_data,batch_size=batch_size,shuffle=True,num_workers=2,pin_memory=True)\n",
        "  valid_loader=DataLoader(valid_data,batch_size=batch_size,shuffle=False,num_workers=2,pin_memory=True)\n",
        "\n",
        "  #optimizer\n",
        "  optim=optimizer.Adam(model.parameters(),lr=learning_rate)\n",
        "  loss_fxn=nn.MSELoss()\n",
        "\n",
        "  # training\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for i in range(epochs):\n",
        "    for batch_features,batch_labels in train_loader:\n",
        "      batch_features,batch_labels=batch_features.to(device),batch_labels.to(device)\n",
        "\n",
        "      # forward propogation\n",
        "      output=model(batch_features)\n",
        "\n",
        "      # loss\n",
        "      loss=loss_fxn(output,batch_labels)\n",
        "\n",
        "      # clear gadient after next backward pass\n",
        "      optim.zero_grad()\n",
        "\n",
        "      # calculating gradient\n",
        "      loss.backward()\n",
        "\n",
        "      # updation_step\n",
        "      optim.step()\n",
        "\n",
        "  # evaluation\n",
        "  model.eval()\n",
        "\n",
        "  batch_actual=[]\n",
        "  batch_pred=[]\n",
        "  train_preds=[]\n",
        "  train_actual=[]\n",
        "  with torch.inference_mode():\n",
        "    for x_batch, y_batch in train_loader:\n",
        "          x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "          preds = model(x_batch)\n",
        "          train_preds.append(preds)\n",
        "          train_actual.append(y_batch)\n",
        "\n",
        "    for batch_features,batch_labels in valid_loader:\n",
        "      batch_features,batch_labels=batch_features.to(device),batch_labels.to(device)\n",
        "      valid_pred=model(batch_features)\n",
        "      batch_pred.append(valid_pred) # store predictions\n",
        "      batch_actual.append(batch_labels) # storing actual value\n",
        "\n",
        "  # batch_actual and batch_loss are list stores predictions from each batch as separate tensors\n",
        "  train_preds = torch.expm1(torch.cat(train_preds))\n",
        "  train_actuals = torch.expm1(torch.cat(train_actual))\n",
        "  val_preds = torch.expm1(torch.cat(batch_pred))\n",
        "  val_actuals = torch.expm1(torch.cat(batch_actual))\n",
        "\n",
        "  # Calculate R² scores\n",
        "  train_r2 = r2_score(train_actuals.cpu().numpy(), train_preds.cpu().numpy())\n",
        "  val_r2 = r2_score(val_actuals.cpu().numpy(), val_preds.cpu().numpy())\n",
        "  # Log values\n",
        "  train_r2_list.append(train_r2)\n",
        "  val_r2_list.append(val_r2)\n",
        "  trial_numbers.append(trial.number)\n",
        "\n",
        "  print(f\"[Trial {trial.number}] Train R2: {train_r2:.4f}, Valid R2: {val_r2:.4f}\")\n",
        "  accuracy_score=val_r2\n",
        "\n",
        "  return accuracy_score"
      ],
      "metadata": {
        "id": "XG90DinFVhaj"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaiaPHQma9W3",
        "outputId": "5fa2c483-4644-4681-c869-2d217245f485"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-09 05:10:10,282] A new study created in memory with name: no-name-80efc111-08ef-4f69-abed-605861a6b554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time=time.time()\n",
        "study.optimize(objective, n_trials=100)\n",
        "end_time=time.time()\n",
        "print(f'Time taken in bayesian search {(end_time-start_time)/60:.4f} min')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBIrZgnOa9T_",
        "outputId": "02ccbb14-b32d-4906-8bb6-43d254fbac1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-32-ccafeeeb921f>:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_tensor=torch.tensor(x_train_transformed,dtype=torch.float32)\n",
            "[I 2025-06-09 05:15:42,003] Trial 0 finished with value: -0.05816531181335449 and parameters: {'num_hidden_layers': 8, 'nueron_per_layer0': 10, 'nueron_per_layer1': 6, 'nueron_per_layer2': 4, 'nueron_per_layer3': 18, 'nueron_per_layer4': 2, 'nueron_per_layer5': 2, 'nueron_per_layer6': 18, 'nueron_per_layer7': 14, 'batch_size': 64, 'activation': 'GELU', 'batch1dnorm': True, 'drop1d': True, 'learning_rate': 0.00014164394886910145, 'keep_prob': 0.18921778736670122, 'No.of.epochs': 900}. Best is trial 0 with value: -0.05816531181335449.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Trial 0] Train R2: -0.0514, Valid R2: -0.0582\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-32-ccafeeeb921f>:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_tensor=torch.tensor(x_train_transformed,dtype=torch.float32)\n",
            "[I 2025-06-09 05:19:42,276] Trial 1 finished with value: 0.7016950845718384 and parameters: {'num_hidden_layers': 8, 'nueron_per_layer0': 16, 'nueron_per_layer1': 2, 'nueron_per_layer2': 16, 'nueron_per_layer3': 4, 'nueron_per_layer4': 6, 'nueron_per_layer5': 10, 'nueron_per_layer6': 6, 'nueron_per_layer7': 2, 'batch_size': 64, 'activation': 'GELU', 'batch1dnorm': True, 'drop1d': False, 'learning_rate': 0.0031887297548378836, 'keep_prob': 0.5973346604169879, 'No.of.epochs': 700}. Best is trial 1 with value: 0.7016950845718384.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Trial 1] Train R2: 0.7708, Valid R2: 0.7017\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-32-ccafeeeb921f>:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_tensor=torch.tensor(x_train_transformed,dtype=torch.float32)\n",
            "[I 2025-06-09 05:22:17,538] Trial 2 finished with value: 0.7954999804496765 and parameters: {'num_hidden_layers': 4, 'nueron_per_layer0': 10, 'nueron_per_layer1': 18, 'nueron_per_layer2': 16, 'nueron_per_layer3': 6, 'batch_size': 64, 'activation': 'GELU', 'batch1dnorm': False, 'drop1d': False, 'learning_rate': 0.012640063796796575, 'keep_prob': 0.5334588679211031, 'No.of.epochs': 600}. Best is trial 2 with value: 0.7954999804496765.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Trial 2] Train R2: 0.8558, Valid R2: 0.7955\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-32-ccafeeeb921f>:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_tensor=torch.tensor(x_train_transformed,dtype=torch.float32)\n",
            "[I 2025-06-09 05:23:14,122] Trial 3 finished with value: 0.07606077194213867 and parameters: {'num_hidden_layers': 6, 'nueron_per_layer0': 14, 'nueron_per_layer1': 16, 'nueron_per_layer2': 4, 'nueron_per_layer3': 18, 'nueron_per_layer4': 4, 'nueron_per_layer5': 8, 'batch_size': 64, 'activation': 'LeakyReLU', 'batch1dnorm': False, 'drop1d': False, 'learning_rate': 0.05474263688399951, 'keep_prob': 0.7035239993113495, 'No.of.epochs': 200}. Best is trial 2 with value: 0.7954999804496765.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Trial 3] Train R2: -0.1103, Valid R2: 0.0761\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-32-ccafeeeb921f>:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_tensor=torch.tensor(x_train_transformed,dtype=torch.float32)\n",
            "[I 2025-06-09 05:27:01,544] Trial 4 finished with value: 0.7476454973220825 and parameters: {'num_hidden_layers': 8, 'nueron_per_layer0': 12, 'nueron_per_layer1': 8, 'nueron_per_layer2': 12, 'nueron_per_layer3': 10, 'nueron_per_layer4': 2, 'nueron_per_layer5': 18, 'nueron_per_layer6': 4, 'nueron_per_layer7': 4, 'batch_size': 128, 'activation': 'ReLU', 'batch1dnorm': False, 'drop1d': False, 'learning_rate': 0.0019111338118524802, 'keep_prob': 0.3878554931077325, 'No.of.epochs': 1000}. Best is trial 2 with value: 0.7954999804496765.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Trial 4] Train R2: 0.8517, Valid R2: 0.7476\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-32-ccafeeeb921f>:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_tensor=torch.tensor(x_train_transformed,dtype=torch.float32)\n",
            "[I 2025-06-09 05:29:53,440] Trial 5 finished with value: -0.05295908451080322 and parameters: {'num_hidden_layers': 4, 'nueron_per_layer0': 14, 'nueron_per_layer1': 12, 'nueron_per_layer2': 16, 'nueron_per_layer3': 14, 'batch_size': 64, 'activation': 'ReLU', 'batch1dnorm': True, 'drop1d': True, 'learning_rate': 0.0021917615103394412, 'keep_prob': 0.10228610685816009, 'No.of.epochs': 500}. Best is trial 2 with value: 0.7954999804496765.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Trial 5] Train R2: -0.0460, Valid R2: -0.0530\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-32-ccafeeeb921f>:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_tensor=torch.tensor(x_train_transformed,dtype=torch.float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iRe3E4LTa9Rc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}